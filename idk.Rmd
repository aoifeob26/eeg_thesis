---
title: "test"
output: html_document
date: "2025-04-02"
---

```{r}
library(fda)
library(dplyr)
library(ggplot2)
library(randomForest)
library(caret)
library(skimr)
library(table1)
library(rpart)
library(rpart.plot)
library(partykit)
library(vip)
library(knitr)
```



```{r}
firsttrial <- readRDS("firsttrial_data.rds")
time <- seq(0, 1, length.out = 256)

# Create Fourier basis
basis_fourier <- create.fourier.basis(rangeval = range(time), nbasis = length(time)/2)
fdParObj <- fdPar(basis_fourier, Lfdobj = 2, lambda = 1e-2)

# FP1
fp1_data <- firsttrial %>% filter(sensor.position == "FP1") %>%
  arrange(matching.condition, subject.identifier, name, time)
mat_fp1 <- matrix(as.numeric(fp1_data$sensor.value), nrow = 256)
fd_fp1 <- smooth.basis(time, mat_fp1, fdParObj)$fd
res_fp1 <- pca.fd(fd_fp1, nharm = 6)
scores_fp1 <- as.data.frame(res_fp1$scores)
colnames(scores_fp1) <- paste0("FP1_", 1:6)

# FP2
fp2_data <- firsttrial %>% filter(sensor.position == "FP2") %>%
  arrange(matching.condition, subject.identifier, name, time)
mat_fp2 <- matrix(as.numeric(fp2_data$sensor.value), nrow = 256)
fd_fp2 <- smooth.basis(time, mat_fp2, fdParObj)$fd
res_fp2 <- pca.fd(fd_fp2, nharm = 6)
scores_fp2 <- as.data.frame(res_fp2$scores)
colnames(scores_fp2) <- paste0("FP2_", 1:6)

# Combine with metadata
meta <- fp1_data %>% filter(time == 0) %>%
  dplyr::select(matching.condition, subject.identifier)
fpca_data <- cbind(meta, scores_fp1, scores_fp2)
fpca_data$subject.identifier <- as.factor(fpca_data$subject.identifier)

```


```{r}
skim(fpca_data)
table1(~ ., data = fpca_data)

```

```{r}
set.seed(123)
train_idx <- createDataPartition(fpca_data$subject.identifier, p = 0.7, list = FALSE)
train_data <- fpca_data[train_idx, ]
test_data <- fpca_data[-train_idx, ]

```

```{r}
tree_model <- rpart(subject.identifier ~ ., data = train_data, method = "class")
rpart.plot(tree_model, box.palette = "Reds", main = "Classification Tree")

tree_pred <- predict(tree_model, test_data, type = "class")
confusionMatrix(tree_pred, test_data$subject.identifier)

```
```{r}
printcp(tree_model)
plotcp(tree_model)
opt_cp <- tree_model$cptable[which.min(tree_model$cptable[,"xerror"]), "CP"]
pruned_tree <- prune(tree_model, cp = opt_cp)
rpart.plot(pruned_tree, box.palette = "Reds", main = "Pruned Tree")

```
```{r}
train_data$matching.condition <- as.factor(train_data$matching.condition)
test_data$matching.condition <- as.factor(test_data$matching.condition)

ctree_model <- ctree(subject.identifier ~ ., data = train_data)

ctree_model <- ctree(subject.identifier ~ ., data = train_data)
plot(ctree_model, main = "Conditional Inference Tree")

ctree_pred <- predict(ctree_model, newdata = test_data)
confusionMatrix(ctree_pred, test_data$subject.identifier)


```
```{r}
rf_model <- randomForest(subject.identifier ~ ., data = train_data, importance = TRUE)
rf_pred <- predict(rf_model, newdata = test_data)

rf_cm <- confusionMatrix(rf_pred, test_data$subject.identifier)
rf_cm

print(paste("Random Forest Accuracy:", round(rf_cm$overall["Accuracy"] * 100, 2), "%"))
print(paste("Kappa:", round(rf_cm$overall["Kappa"], 2)))

varImpPlot(rf_model)

```

```{r}
control <- trainControl(method = "cv", number = 5)
rf_tuned <- train(subject.identifier ~ ., data = train_data,
                  method = "rf", trControl = control, tuneLength = 5)

rf_pred <- predict(rf_tuned, newdata = test_data)
confusionMatrix(rf_pred, test_data$subject.identifier)

plot(rf_tuned)
vip(rf_tuned$finalModel, num_features = 10)

```
```{r}
ggplot(fpca_data, aes(x = subject.identifier, y = FP2_6)) +
  geom_boxplot(fill = "lightblue") +
  labs(title = "FP2_6 by Subject Group", x = "Subject Group", y = "FP2_6")

```

```{r}
model_comp <- data.frame(
  Model = c(
    "Pruned Classification Tree (rpart)",
    "Conditional Inference Tree (ctree)",
    "Random Forest (untuned)",
    "Tuned Random Forest"
  ),
  Accuracy = c("54.2%", "45.8%", "62.5%", "70.8%"),  # Replace with your actual results
  Kappa = c("0.12", "0.00", "0.25", "0.42"),
  Top.Features.Used = c(
    "FP2_6, FP1_1",
    "None (no split)",
    "FP2_6, FP2_5, FP1_1",
    "FP2_6, FP1_3, FP2_2"
  ),
  Interpretability = c(
    "High (easy to interpret)",
    "Very low",
    "Medium",
    "Lower (but best performance)"
  )
)

knitr::kable(
  model_comp,
  caption = "Comparison of Tree-Based Models for Subject Classification",
  align = "lccccl"
)

```

