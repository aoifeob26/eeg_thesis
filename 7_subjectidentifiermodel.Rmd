---
title: "subject identifier model"
output: html_document
date: "2025-03-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Load necessary libraries
library(tidyverse)
library(fda)
library(nnet)
library(caret)
library(glmnet)
library(randomForest)

# Load dataset
firsttrial <- readRDS("firsttrial_data.rds")
```


```{r}
# Combine FP1 ordering data with FP1 and FP2 FPCA scores
fpca_scores <- cbind(fp1_order, scores, scores2)
```


```{r}
#Helper Function to Fit Multinomial Model Dynamically 
fit_multinom_model <- function(data, predictors, target) {
  formula_str <- paste(target, "~", paste(predictors, collapse = " + "))
  formula_obj <- as.formula(formula_str)
  model <- nnet::multinom(formula_obj, data = data)
  return(model)
}

```


### Train-Test Split and Model Evaluation

```{r}
set.seed(123)  
 # clustering functions kmeans etc

## Partition the data into 75% training and 25% testing based on subject.identifier
train_indices <- createDataPartition(fpca_scores$subject.identifier, p =0.75, list=F) 

as.vector(train_indices)

train_scores <- fpca_scores[train_indices, ]
test_scores <- fpca_scores[-train_indices, ]
train_condition <- train_scores$condition_factor
test_condition <- test_scores$condition_factor



train_scores_df <- data.frame(train_scores)
test_scores_df <- data.frame(test_scores)
```


```{r}
## Partition the data into 75% training and 25% testing based on subject.identifier
fp1_vars <- grep("^FP1\\.", names(train_scores_df), value = TRUE)
train_model_fp1 <- fit_multinom_model(train_scores_df, fp1_vars, "train_condition")


## Generate predictions on the test set and create a confusion matrix to evaluate performance
predictions <- predict(train_model_fp1, newdata = test_scores_df)


confusion_matrix <- table(predictions, test_condition)
print(confusion_matrix)


## Calculate and print the model's prediction accuracy
accuracy <- sum(predictions == test_condition) / length(test_condition)
print(accuracy)


```

Multinomial Model Using FP2 Scores Only

```{r}

## Train a multinomial logistic regression model using only the FP2 principal component scores.
fp2_vars <- grep("^FP2\\.", names(train_scores_df), value = TRUE)
train_model_fp2 <- fit_multinom_model(train_scores_df, fp2_vars, "train_condition")


predictions <- predict(train_model_fp2, newdata = test_scores_df)

## Create a confusion matrix to compare predictions to actual test conditions.
confusion_matrix <- table(predictions, test_condition)
print(confusion_matrix)

## Calculate and print the accuracy of the FP2 model on the test set.
accuracy <- sum(predictions == test_condition) / length(test_condition)
print(accuracy)
```



# Train multinomial logistic regression model using FP1 & FP2 scores
```{r}
fp_vars <- grep("^FP[12]\\.", names(train_scores_df), value = TRUE)
train_model_combined <- fit_multinom_model(train_scores_df, fp_vars, "train_condition")


# Predict on test data
predictions_combined <- predict(train_model_combined, newdata = test_scores_df)

# Confusion matrix & accuracy
conf_matrix_combined <- table(predictions_combined, test_condition)
print(conf_matrix_combined)

accuracy_combined <- sum(predictions_combined == test_condition) / length(test_condition)
print(paste("Multinomial Model Accuracy:", round(accuracy_combined * 100, 2), "%"))
```

# Random forest

```{r}
#Function to fit Random Forest model dynamically
fit_random_forest <- function(data, predictors, target, ntree = 500) {
  # Ensure target is a factor for classification
  data[[target]] <- as.factor(data[[target]])
  
  # Build formula dynamically
  formula_str <- paste(target, "~", paste(predictors, collapse = " + "))
  formula_obj <- as.formula(formula_str)
  
  # Fit the model
  rf_model <- randomForest(formula_obj, data = data, ntree = ntree, importance = TRUE)
  return(rf_model)
}

# Select predictors dynamically (FP1 + FP2) 
fp_vars <- grep("^FP[12]\\.", names(train_scores_df), value = TRUE)

# Fit the Random Forest model 
rf_model <- fit_random_forest(train_scores_df, fp_vars, "subject.identifier")

# Predict on test data 
rf_predictions <- predict(rf_model, newdata = test_scores_df)

# Evaluate performance 
conf_matrix <- table(rf_predictions, test_scores_df$subject.identifier)
print(conf_matrix)

rf_accuracy <- mean(rf_predictions == test_scores_df$subject.identifier)
print(paste("Random Forest Accuracy:", round(rf_accuracy * 100, 2), "%"))

importance(rf_model)

```

```{r}
# Selecting only the most important FP1 & FP2 components
important_features <- c("FP2.3","FP2.2","FP1.1")

# Train multinomial model again
train_model_selected <- nnet::multinom(subject.identifier ~ ., data = train_scores_df[, c("subject.identifier", important_features)], maxit = 1000)

# Predict again
predictions_selected <- predict(train_model_selected, newdata = test_scores_df[, important_features])

# Confusion matrix & accuracy
conf_matrix_selected <- table(predictions_selected, test_condition)
print(conf_matrix_selected)

accuracy_selected <- sum(predictions_selected == test_condition) / length(test_condition)
print(paste("Multinomial Model Accuracy (Selected Features):", round(accuracy_selected * 100, 2), "%"))

```


```{r}
set.seed(123)
# train_indices <- createDataPartition(fpca_scores$subject.identifier, p = 0.75, list = FALSE)
# train_data <- fpca_scores[train_indices, ]
# test_data <- fpca_scores[-train_indices, ]

# Convert response variable to numeric for glmnet
y_train <- as.numeric(as.factor(train_scores$subject.identifier)) - 1
y_test <- as.numeric(as.factor(test_scores$subject.identifier)) - 1

# Prepare predictor matrices
X_train <- as.matrix(train_scores %>% dplyr::select(starts_with("FP")))
X_test <- as.matrix(test_scores %>% dplyr::select(starts_with("FP")))

# Standardize predictors
X_train <- scale(X_train)
X_test <- scale(X_test)

lasso_model <- cv.glmnet(X_train, y_train, alpha = 1, family = "multinomial")

train_scores$subject.identifier <- as.factor(train_scores$subject.identifier)


# Predict on test set
lasso_pred <- predict(lasso_model, X_test, s = "lambda.min", type = "class")

# Convert predictions back to factors
lasso_pred <- factor(as.numeric(lasso_pred), levels = unique(y_train), labels = levels(train_scores$subject.identifier))

# Compute accuracy
accuracy_lasso <- mean(lasso_pred == test_scores$subject.identifier)
print(paste("LASSO Model Accuracy:", round(accuracy_lasso * 100, 2), "%"))
```

