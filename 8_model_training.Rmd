---
title: "6_model_training"
output: html_document
date: "2025-03-04"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(fda.usc)
library(caret)
```

```{r}
firsttrial <- readRDS("firsttrial_data.rds")

head(firsttrial)
summary(firsttrial)
```

Train-Test Split and Model Evaluation

```{r}

set.seed(123)  
  # clustering functions kmeans etc

## Partition the data into 75% training and 25% testing based on subject.identifier
train_indices <- createDataPartition(fp1modeldata$subject.identifier, p =0.75, list=F) #matching condition and subject identifier

as.vector(train_indices)

train_scores <- fp1modeldata[train_indices, ]
test_scores <- fp1modeldata[-train_indices, ]
train_condition <- train_scores$condition_factor
test_condition <- test_scores$condition_factor



train_scores_df <- data.frame(train_scores)
test_scores_df <- data.frame(test_scores)

## Partition the data into 75% training and 25% testing based on subject.identifier
train_model_fp1 <- multinom(train_condition ~ FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5 , data = train_scores_df)

## Generate predictions on the test set and create a confusion matrix to evaluate performance
predictions <- predict(train_model_fp1, newdata = test_scores_df)


confusion_matrix <- table(predictions, test_condition)
print(confusion_matrix)


## Calculate and print the model's prediction accuracy
accuracy <- sum(predictions == test_condition) / length(test_condition)
print(accuracy)


```


Multinomial Model Using FP2 Scores Only

```{r}

## Train a multinomial logistic regression model using only the FP2 principal component scores.
## The model predicts the matching condition (stored in 'train_condition') based on FP2 scores
train_model_fp2 <- multinom(train_condition ~ FP2.1 + FP2.2 + FP2.3 + FP2.4 + FP2.5 , data = train_scores_df)


predictions <- predict(train_model_fp2, newdata = test_scores_df)

## Create a confusion matrix to compare predictions to actual test conditions.
confusion_matrix <- table(predictions, test_condition)
print(confusion_matrix)

## Calculate and print the accuracy of the FP2 model on the test set.
accuracy <- sum(predictions == test_condition) / length(test_condition)
print(accuracy)
```

Multinomial Model Using FP1 Scores Only

```{r}
## Partition the data based on subject identifier (via condition_factor) into training and test sets.
## 'fp1_order' contains FP1 data at time 0; we use this along with FPCA scores.
train_indices <- createDataPartition(fp1modeldata$subject.identifier, p =0.75, list=F) #matching condition and subject identifier

as.vector(train_indices)

train_scores <- fp1modeldata[train_indices, ]
test_scores <- fp1modeldata[-train_indices, ]
train_condition <- train_scores$condition_factor
test_condition <- test_scores$condition_factor



train_scores_df <- data.frame(train_scores)
test_scores_df <- data.frame(test_scores)

## Train a multinomial logistic regression model using FP1 principal component scores.
## This model predicts the matching condition (condition_factor) from FP1 scores.
train_model_fp1 <- multinom(train_condition ~ FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5 , data = train_scores_df)

## Predict matching conditions on the test dataset using the FP1 model.
predictions <- predict(train_model_fp1, newdata = test_scores_df)

## Build a confusion matrix to compare predicted vs. actual matching conditions.
confusion_matrix <- table(predictions, test_condition)
print(confusion_matrix)

## Calculate and print the model accuracy for the FP1-based predictions
accuracy <- sum(predictions == test_condition) / length(test_condition)
print(accuracy)

```

accuracy really low above

Combined FP1 & FP2 Model and Alternative GLMNET Approach

```{r}
## Set seed for reproducibility and prepare FP1 and FP2 data by filtering and arranging by subject, condition, and time.
set.seed(123)  
fp1_data <- firsttrial %>%
  filter(sensor.position == "FP1") %>%
  dplyr::select(name, subject.identifier, matching.condition, time, sensor.value) %>%
  arrange(subject.identifier, matching.condition, name, time)

fp2_data <- firsttrial %>%
  filter(sensor.position == "FP2") %>%
  dplyr::select(name, subject.identifier, matching.condition, time, sensor.value) %>%
  arrange(subject.identifier, matching.condition, name, time)
```

```{r}

## Create training and testing splits based on the condition factor (which is the subject identifier)
## using a 75% train and 25% test split.
train_indices <- createDataPartition(fp1modeldata$condition_factor, p = 0.75, list = FALSE)
train_data <- fp1modeldata[train_indices, ]
test_data <- fp1modeldata[-train_indices, ]

## First model: Train a multinomial logistic regression model to predict the condition factor
## (subject identifier) using combined FP1 and FP2 principal component scores.
train_model <- multinom(condition_factor ~ 
                          FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5 + 
                          FP2.1 + FP2.2 + FP2.3 + FP2.4 + FP2.5, 
                          data = train_data)

## Generate predictions on the test set using the multinom model,
## then create and print a confusion matrix to assess model performance.
predictions <- predict(train_model, newdata = test_data)

confusion_matrix <- table(predictions, test_data$condition_factor)
print(confusion_matrix)

## Calculate and print the prediction accuracy for the model predicting the condition factor.
accuracy <- sum(predictions == test_data$condition_factor) / length(test_data$condition_factor)
print(accuracy)

## Second model: Re-create fp1modeldata by combining fp1_order with FP1 and FP2 scores (if needed again).
fp1modeldata <- cbind(fp1_order, scores_fp1, scores_fp2)

fp1modeldata <- cbind(fp1_order, scores_fp1, scores_fp2)

train_indices <- createDataPartition(fp1modeldata$subject.identifier, p = 0.75, list = FALSE)
train_data <- fp1modeldata[train_indices, ]
test_data <- fp1modeldata[-train_indices, ]

## Train a multinomial logistic regression model to predict the subject.identifier using the FPCA scores.
train_model <- multinom(subject.identifier ~ 
                          FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5 + 
                          FP2.1 + FP2.2 + FP2.3 + FP2.4 + FP2.5, 
                          data = train_data)

train_model <- glmnet::glmnet(subject.identifier ~ 
                          FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5 + 
                          FP2.1 + FP2.2 + FP2.3 + FP2.4 + FP2.5, 
                          data = train_data)

## Generate predictions using the glmnet model on the test set.
predictions <- predict(train_model, newdata = test_data)

## Build a confusion matrix comparing predictions to the actual subject.identifier in the test set
confusion_matrix <- table(predictions, test_data$subject.identifier)
print(confusion_matrix)

## Calculate and print the prediction accuracy for the glmnet model predicting subject.identifier.
accuracy <- sum(predictions == test_data$subject.identifier) / length(test_data$subject.identifier)
print(accuracy)
```

