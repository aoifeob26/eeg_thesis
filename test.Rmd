---
title: "test"
output: html_document
date: "2025-03-04"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(tidyr)
library(nnet)
library(fda)
library(caret)
library(glmnet)
```


```{r}

# Get the names of all the files in the data folder underneath the folder this Rmd file is saved in
filenames <- list.files("/Users/21349803/OneDrive - National University of Ireland, Galway/HDS Project/data/SMNI_CMI_TEST/Test")

# Set up a blank list to hold the data
files <- list()

# Loop over all the files in the folder
for(i in 1:length(filenames)){
  # For each filename, read it in
  cleaned_data <- read.csv(paste0("/Users/21349803/OneDrive - National University of Ireland, Galway/HDS Project/data/SMNI_CMI_TEST/Test/", filenames[i]))
  
  # Perform some cleaning, e.g., selecting only certain sensors
  cleaned_data <- cleaned_data %>%
    # Filter for specific sensors, e.g., "FP1" and "FP2"
    filter(sensor.position %in% c("FP1", "FP2")) %>%
    
    # Mutate to ensure categorical variables are factors
    mutate(
      sensor.position = as.factor(sensor.position),
      subject.identifier = as.factor(subject.identifier),
      trial.number = as.factor(trial.number)
    ) %>%
    
    # Arrange data by trial number and time
    arrange(trial.number, time)
  
  # Now save the cleaned data into the list
  files[[i]] <- cleaned_data
}

# Combine the list into a data frame
dat <- do.call(rbind, files)

# View cleaned data
head(dat)
summary(dat)


```

functional t-test

take subsample of s1obj and one trial number

sample(1:10, ) unique(dat\$name)

```{r}
dat$trial.number = as.numeric(as.character(dat$trial.number))

datsmall=dat%>%filter(time==0)

datS1 = datsmall %>% filter(matching.condition=="S1 obj")


firsttrial = datS1 %>%
  group_by(name) %>%
  mutate(mintrial = as.numeric(min(trial.number))) %>%
  ungroup() %>%
  filter(trial.number==mintrial)

firsttrial = datsmall %>%
  group_by(name, matching.condition) %>%
  mutate(mintrial = as.numeric(min(trial.number))) %>%
  ungroup() %>%
  filter(trial.number==mintrial)

firsttrial = dat %>%
  group_by(name, matching.condition, sensor.position, time) %>%
  mutate(mintrial = as.numeric(min(trial.number))) %>%
  ungroup() %>%
  filter(trial.number==mintrial)

firsttrial %>% filter(sensor.position  %in% c("FP1", "FP2"),
                      name != "co2a0000371") %>%
  ggplot(aes(x=time,y=sensor.value, 
       color = matching.condition)) +
  geom_line() + theme(legend.position = "none") + 
  facet_wrap(~name)


firsttrial %>% filter(sensor.position  %in% c("FP1", "FP2"),
                      name == "co2a0000364") %>%
  ggplot(aes(x=time,y=sensor.value, 
       color = subject.identifier)) +
  geom_line() + theme(legend.position = "none") + 
  facet_wrap(~name)


firsttrial %>% filter(sensor.position  %in% c("FP1", "FP2"),
                      name != "co2a0000371") %>%
  ggplot(aes(x=time,y=sensor.value, 
       color = matching.condition)) +
  geom_smooth() 

firsttrial %>% filter(sensor.position  %in% c("FP1", "FP2"),
                      name != "co2a0000371") %>%
  ggplot(aes(x=time,y=sensor.value, 
       color = subject.identifier)) +
  geom_smooth() + facet_wrap(~matching.condition) + theme_bw()



```


```{r}
firsttrial <- readRDS("firsttrial_data.rds")  
```


Define the Time Grid 

```{r}
time <- seq(0, 1, length.out = 256)
```

Basis Parameters 

```{r}
norder <- 10
nbasis <- length(time) + norder - 2
basis <- create.bspline.basis(range(time), nbasis, norder, time)

Lfdobj <- 4    
lambda <- 1e-2
fdParObj <- fdPar(fd(matrix(0, nbasis, 1), basis), Lfdobj, lambda)

```

Smoothing Function

```{r}
smooth_fd <- function(sensor_matrix, time, fdParObj) {
  smooth.basis(time, sensor_matrix, fdParObj)$fd
}
```

```{r}
# Extract the control data for FP1 and S1 obj
control_simple <- firsttrial %>%
  filter(sensor.position == "FP1", matching.condition == "S1 obj", subject.identifier == "c") %>%
 dplyr:: select(name, time, sensor.value)

# Convert sensor values to a matrix (assuming 256 time points and 8 trials)
controlfd <- matrix(as.numeric(control_simple$sensor.value), nrow = 256, ncol = 8)

# Now you can smooth it
control_fd <- smooth_fd(controlfd, time, fdParObj)

```
```{r}
# Extract alcohol data for FP1 and S1 obj
alcohol_simple <- firsttrial %>%
  filter(sensor.position == "FP1", matching.condition == "S1 obj", subject.identifier == "a") %>%
 dplyr:: select(name, time, sensor.value)

# Convert sensor values to a matrix (assuming 256 time points and 8 trials)
alcoholfd <- matrix(as.numeric(alcohol_simple$sensor.value), nrow = 256, ncol = 8)

# Now smooth the matrix to create a functional data object
alcohol_fd <- smooth_fd(alcoholfd, time, fdParObj)

```


```{r}
control_fd <- smooth_fd(controlfd, time, fdParObj)
alcohol_fd <- smooth_fd(alcoholfd, time, fdParObj)
```

Extract Data

```{r}
control_simple <- firsttrial %>%
  filter(sensor.position == "FP1", matching.condition == "S1 obj", subject.identifier == "c") %>%
 dplyr:: select(name, time, sensor.value)

```


Convert to matrix

```{r}
controlfd <- matrix(as.numeric(control_simple$sensor.value), nrow = 256, ncol = 8)

```

```{r}
# Helper function to extract, convert, and smooth data
get_smoothed_fd <- function(firsttrial, sensor, condition, subject, nrow_matrix, time, fdParObj) {
  df <- firsttrial %>%
    filter(sensor.position == sensor,
           matching.condition == condition,
           subject.identifier == subject) %>%
   dplyr:: select(name, time, sensor.value)
  
  sensor_matrix <- matrix(as.numeric(df$sensor.value), nrow = nrow_matrix)
  smooth_fd(sensor_matrix, time, fdParObj)
}
```


```{r}
# FP1 and S1 obj (control and alcohol)
fp1_s1obj_control <- get_smoothed_fd(firsttrial, "FP1", "S1 obj", "c", 256, time, fdParObj)
fp1_s1obj_alcohol <- get_smoothed_fd(firsttrial, "FP1", "S1 obj", "a", 256, time, fdParObj)

# FP2 and S2 match (control and alcohol)
fp2_s2match_control <- get_smoothed_fd(firsttrial, "FP2", "S2 match", "c", 256, time, fdParObj)
fp2_s2match_alcohol <- get_smoothed_fd(firsttrial, "FP2", "S2 match", "a", 256, time, fdParObj)

# FP2 and S2 nomatch (control and alcohol)
fp2_s2nomatch_control <- get_smoothed_fd(firsttrial, "FP2", "S2 nomatch,", "c", 256, time, fdParObj)
fp2_s2nomatch_alcohol <- get_smoothed_fd(firsttrial, "FP2", "S2 nomatch,", "a", 256, time, fdParObj)

# FP1 and S2 match (control and alcohol)
fp1_s2match_control <- get_smoothed_fd(firsttrial, "FP1", "S2 match", "c", 256, time, fdParObj)
fp1_s2match_alcohol <- get_smoothed_fd(firsttrial, "FP1", "S2 match", "a", 256, time, fdParObj)

# FP1 and S2 nomatch (control and alcohol)
fp1_s2nomatch_control <- get_smoothed_fd(firsttrial, "FP1", "S2 nomatch,", "c", 256, time, fdParObj)
fp1_s2nomatch_alcohol <- get_smoothed_fd(firsttrial, "FP1", "S2 nomatch,", "a", 256, time, fdParObj)

```

```{r}
# Now perform t-tests between control and alcohol for each condition:

# T-test for FP1 S1 obj
t_test_fp1_s1obj <- tperm.fd(fp1_s1obj_control, fp1_s1obj_alcohol)
print("T-test for FP1 S1 obj (Control vs Alcohol):")
print(t_test_fp1_s1obj)

# T-test for FP2 S2 match
t_test_fp2_s2match <- tperm.fd(fp2_s2match_control, fp2_s2match_alcohol)
print("T-test for FP2 S2 match (Control vs Alcohol):")
print(t_test_fp2_s2match)

# T-test for FP2 S2 nomatch
t_test_fp2_s2nomatch <- tperm.fd(fp2_s2nomatch_control, fp2_s2nomatch_alcohol)
print("T-test for FP2 S2 nomatch (Control vs Alcohol):")
print(t_test_fp2_s2nomatch)

# T-test for FP1 S2 match
t_test_fp1_s2match <- tperm.fd(fp1_s2match_control, fp1_s2match_alcohol)
print("T-test for FP1 S2 match (Control vs Alcohol):")
print(t_test_fp1_s2match)

# T-test for FP1 S2 nomatch
t_test_fp1_s2nomatch <- tperm.fd(fp1_s2nomatch_control, fp1_s2nomatch_alcohol)
print("T-test for FP1 S2 nomatch (Control vs Alcohol):")
print(t_test_fp1_s2nomatch)


# Save control functional data object
saveRDS(fp1_s2nomatch_control, file = "fp1_control_fd.rds")

# Save alcoholic functional data object
saveRDS(fp1_s2nomatch_alcohol, file = "fp1_alcohol_fd.rds")

# Run the permutation test
t_test_fp1_s2nomatch <- tperm.fd(fp1_s2nomatch_control, fp1_s2nomatch_alcohol)

# Save the test result
saveRDS(t_test_fp1_s2nomatch, file = "t_test_fp1_s2nomatch.rds")



```

```{r}
# Define the time grid for 256 points between 0 and 1
time <- seq(0, 1, length.out = 256)

# Define B-spline basis parameters for smoothing FPCA data
norder <- 10
nbasis <- length(time) + norder - 2
basis <- create.bspline.basis(range(time), nbasis, norder, time)

# Define the penalty and smoothing parameter
Lfdobj <- 4    
lambda <- 1e-2
fdParObj <- fdPar(fd(matrix(0, nbasis, 1), basis), Lfdobj, lambda)

# Smoothing helper function: converts a sensor matrix into a functional data object.
smooth_fd <- function(sensor_matrix, time, fdParObj) {
  smooth.basis(time, sensor_matrix, fdParObj)$fd
}
```


```{r}
# Extract FP1 sensor data from firsttrial for FP1
fp1_pca <- firsttrial %>%
  filter(sensor.position == "FP1") %>%
dplyr::  select(name, time, sensor.value)

# Convert sensor values to a matrix (256 time points x 48 trials)
pca_fd_matrix <- matrix(as.numeric(fp1_pca$sensor.value), nrow = 256, ncol = 48)

# Smooth the matrix data to create a functional data object
pca_fd <- smooth.basis(time, pca_fd_matrix, fdParObj)$fd

# Perform FPCA to extract 5 principal components and plot the results
res_fp1 <- pca.fd(pca_fd, nharm = 20)
plot(res_fp1)

```


```{r}
# Extract FP1 sensor data for S1 obj (subject "a")
s1_data <- firsttrial %>%
  filter(sensor.position == "FP1", matching.condition == "S1 obj", subject.identifier == "a") %>%
  dplyr:: select(name, time, sensor.value)

# Convert sensor values to a matrix (256 time points x 8 trials)
s1_fd_matrix <- matrix(as.numeric(s1_data$sensor.value), nrow = 256, ncol = 8)

# Smooth the matrix to obtain a functional data object
s1_fd <- smooth.basis(time, s1_fd_matrix, fdParObj)$fd

# Extract FP1 sensor data for S2 match (subject "a")
s2_match_data <- firsttrial %>%
  filter(sensor.position == "FP1", matching.condition == "S2 match", subject.identifier == "a") %>%
 dplyr:: select(name, time, sensor.value)

# Convert sensor values to a matrix and smooth it
s2_match_fd_matrix <- matrix(as.numeric(s2_match_data$sensor.value), nrow = 256, ncol = 8)
s2_match_fd <- smooth.basis(time, s2_match_fd_matrix, fdParObj)$fd

# Perform FPCA for S2 match condition (FP1 sensor)
res_s2m <- pca.fd(s2_match_fd, nharm = 20)
plot(res_s2m)

# Extract FP1 sensor data for S2 nomatch (subject "a")
s2_nomatch_data <- firsttrial %>%
  filter(sensor.position == "FP1", matching.condition == "S2 nomatch,", subject.identifier == "a") %>%
 dplyr:: select(name, time, sensor.value)

# Convert sensor values to a matrix and smooth it
s2_nomatch_fd_matrix <- matrix(as.numeric(s2_nomatch_data$sensor.value), nrow = 256, ncol = 8)
s2_nomatch_fd <- smooth.basis(time, s2_nomatch_fd_matrix, fdParObj)$fd

# Perform FPCA for S2 nomatch condition (FP1 sensor) with 4 components
res_s2no <- pca.fd(s2_nomatch_fd, nharm = 20)
plot(res_s2no)

```


```{r}
t_test_s1_s2match <- tperm.fd(s1_fd, s2_match_fd)
t_test_s1_s2nomatch <- tperm.fd(s1_fd, s2_nomatch_fd)
t_test_s2match_s2nomatch <- tperm.fd(s2_match_fd, s2_nomatch_fd)

print(t_test_s1_s2match)

print(t_test_s1_s2nomatch)

print(t_test_s2match_s2nomatch)

```


```{r}
# Extract FP1 ordering data at time 0 for modeling
fp1_order <- firsttrial %>%
  filter(sensor.position == "FP1") %>%
  dplyr:: select(name, subject.identifier, matching.condition, time, sensor.value) %>%
  filter(time == 0) %>%
  arrange(subject.identifier, matching.condition, name)

# Extract the full FP1 time series data
fp1_data <- firsttrial %>%
  filter(sensor.position == "FP1") %>%
 dplyr::  select(name, subject.identifier, matching.condition, time, sensor.value) %>%
  arrange(subject.identifier, matching.condition, name, time)

```


```{r}
# Convert FP1 data to a matrix (256 x 48) and smooth it
pca_matrix_fp1 <- matrix(as.numeric(fp1_data$sensor.value), nrow = 256, ncol = 48)
pca_fd_fp1 <- smooth.basis(time, pca_matrix_fp1, fdParObj)$fd

# Run FPCA to extract 5 principal components
resfp1 <- pca.fd(pca_fd_fp1, nharm = 20)
plot(resfp1)

# Extract FPCA scores and prepare modeling data
scores <- data.frame(resfp1$scores)
colnames(scores) <- paste0("FP1.", 1:5)

# Create a factor for the condition based on matching.condition
fp1_order$condition_factor <- factor(fp1_order$matching.condition)

# Combine ordering information with FPCA scores
fp1modeldata <- cbind(fp1_order, scores)

# Build a multinomial logistic regression model using FP1 scores
model_fp1 <- multinom(condition_factor ~ FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5, 
                      data = fp1modeldata)
summary(model_fp1)

```


```{r}
# Extract FP2 data
fp2_data <- firsttrial %>%
  filter(sensor.position == "FP2") %>%
  dplyr:: select(name, subject.identifier, matching.condition, time, sensor.value) %>%
  arrange(subject.identifier, matching.condition, name, time)

# Convert FP2 sensor data into a matrix (256 x 48) and smooth it
pca_matrix_fp2 <- matrix(as.numeric(fp2_data$sensor.value), nrow = 256, ncol = 48)
pca_fd_fp2 <- smooth.basis(time, pca_matrix_fp2, fdParObj)$fd

# Run FPCA on FP2 data to extract 5 principal components
resfp2 <- pca.fd(pca_fd_fp2, nharm = 20)
plot(resfp2)

# Extract FP2 scores
scores2 <- data.frame(resfp2$scores)
colnames(scores2) <- paste0("FP2.", 1:5)

```


```{r}
# Combine FP1 ordering data with FP1 and FP2 FPCA scores
fp1modeldata <- cbind(fp1_order, scores, scores2)

# Build a multinom model predicting subject identifier using combined scores
model_combined <- multinom(subject.identifier ~ FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5 +
                             FP2.1 + FP2.2 + FP2.3 + FP2.4 + FP2.5, 
                           data = fp1modeldata)
summary(model_combined)

```

```{r}
## Extract FP1 sensor data at time 0, arrange by subject and condition for modeling
 
fp1_order <- firsttrial %>%
  filter(sensor.position == "FP1") %>%
  dplyr::select(name,subject.identifier, matching.condition, time, sensor.value) %>%
  filter(time==0) %>%
  arrange(subject.identifier, matching.condition, name)

fp1_data <- firsttrial %>%
  filter(sensor.position == "FP1") %>%
  dplyr::select(name,subject.identifier, matching.condition, time, sensor.value) %>%
  arrange(subject.identifier, matching.condition, name, time)

## Convert the FP1 time series data into a matrix form and smooth it to get the functional data object
pca_matrix <- matrix(as.numeric(fp1_data$sensor.value), 
                     nrow = 256, ncol = 48)

## Apply FPCA to extract 5 principal components and plot the FPCA results
pca_fd <- smooth.basis(time, pca_matrix, fdParObj)$fd
resfp1 <- pca.fd(pca_fd, nharm = 20)

plot(resfp1)


scores <- data.frame(resfp1$scores)
colnames(scores) <- c("FP1.1", "FP1.2", "FP1.3", "FP1.4", "FP1.5")
fp1_order$condition_factor <- factor(fp1_order$matching.condition)
#condition <- c(rep("S1 obj", 16), rep("S2 match", 16), rep("S2 No match,", 16))
#condition_factor <- factor(condition, levels = c("S1 obj", "S2 match", "S2 No match,"))
fp1modeldata = cbind(fp1_order,scores)

model <- multinom(condition_factor ~ FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5, data = fp1modeldata)


summary(model)
```

Building a Multinomial Model with FP1 and FP2 Data

```{r}
fp2_data <- firsttrial %>%
  filter(sensor.position == "FP2") %>%
  dplyr::select(name,subject.identifier, matching.condition, time, sensor.value) %>%
  arrange(subject.identifier, matching.condition, name, time)

## Convert the FP2 data into a matrix and smooth it to create a functional data object
pca_matrix <- matrix(as.numeric(fp2_data$sensor.value), 
                     nrow = 256, ncol = 48)


pca_fd <- smooth.basis(time, pca_matrix, fdParObj)$fd
resfp2 <- pca.fd(pca_fd, nharm = 20)

plot(resfp2)


scores2 <- data.frame(resfp2$scores)
colnames(scores2) <- c("FP2.1", "FP2.2", "FP2.3", "FP2.4", "FP2.5")

fp1modeldata = cbind(fp1_order,scores, scores2)

## Build a multinomial logistic regression model to predict subject identifier using combined FP1 & FP2 scores
model <- multinom(subject.identifier ~ FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5 + FP2.1 + FP2.2 + FP2.3 + FP2.4 + FP2.5, data = fp1modeldata)


summary(model)
```

Train-Test Split and Model Evaluation

```{r}

set.seed(123)  
 # clustering functions kmeans etc

## Partition the data into 75% training and 25% testing based on subject.identifier
train_indices <- createDataPartition(fp1modeldata$subject.identifier, p =0.75, list=F) #matching condition and subject identifier

as.vector(train_indices)

train_scores <- fp1modeldata[train_indices, ]
test_scores <- fp1modeldata[-train_indices, ]
train_condition <- train_scores$condition_factor
test_condition <- test_scores$condition_factor



train_scores_df <- data.frame(train_scores)
test_scores_df <- data.frame(test_scores)

## Partition the data into 75% training and 25% testing based on subject.identifier
train_model_fp1 <- multinom(train_condition ~ FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5 , data = train_scores_df)

## Generate predictions on the test set and create a confusion matrix to evaluate performance
predictions <- predict(train_model_fp1, newdata = test_scores_df)


confusion_matrix <- table(predictions, test_condition)
print(confusion_matrix)


## Calculate and print the model's prediction accuracy
accuracy <- sum(predictions == test_condition) / length(test_condition)
print(accuracy)


```

Multinomial Model Using FP2 Scores Only

```{r}

## Train a multinomial logistic regression model using only the FP2 principal component scores.
## The model predicts the matching condition (stored in 'train_condition') based on FP2 scores
train_model_fp2 <- multinom(train_condition ~ FP2.1 + FP2.2 + FP2.3 + FP2.4 + FP2.5 , data = train_scores_df)


predictions <- predict(train_model_fp2, newdata = test_scores_df)

## Create a confusion matrix to compare predictions to actual test conditions.
confusion_matrix <- table(predictions, test_condition)
print(confusion_matrix)

## Calculate and print the accuracy of the FP2 model on the test set.
accuracy <- sum(predictions == test_condition) / length(test_condition)
print(accuracy)
```

Multinomial Model Using FP1 Scores Only

```{r}
## Partition the data based on subject identifier (via condition_factor) into training and test sets.
## 'fp1_order' contains FP1 data at time 0; we use this along with FPCA scores.
train_indices <- createDataPartition(fp1modeldata$subject.identifier, p =0.75, list=F) #matching condition and subject identifier

as.vector(train_indices)

train_scores <- fp1modeldata[train_indices, ]
test_scores <- fp1modeldata[-train_indices, ]
train_condition <- train_scores$condition_factor
test_condition <- test_scores$condition_factor



train_scores_df <- data.frame(train_scores)
test_scores_df <- data.frame(test_scores)

## Train a multinomial logistic regression model using FP1 principal component scores.
## This model predicts the matching condition (condition_factor) from FP1 scores.
train_model_fp1 <- multinom(train_condition ~ FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5 , data = train_scores_df)

## Predict matching conditions on the test dataset using the FP1 model.
predictions <- predict(train_model_fp1, newdata = test_scores_df)

## Build a confusion matrix to compare predicted vs. actual matching conditions.
confusion_matrix <- table(predictions, test_condition)
print(confusion_matrix)

## Calculate and print the model accuracy for the FP1-based predictions
accuracy <- sum(predictions == test_condition) / length(test_condition)
print(accuracy)

```

accuracy really low above


```{r}
# Extract the scores and convert them to a matrix
predictors <- as.matrix(fp1modeldata[, c("FP1.1", "FP1.2", "FP1.3", "FP1.4", "FP1.5", "FP2.1", "FP2.2", "FP2.3", "FP2.4", "FP2.5")])

# Convert the outcome variable into a factor for multinomial regression
response <- as.factor(fp1modeldata$matching.condition)

# Fit the Lasso model with cross-validation
lasso_model <- cv.glmnet(predictors, response, alpha = 1, family = "multinomial", type.measure = "class")

# Print the best lambda value
print(paste("Best lambda: ", lasso_model$lambda.min))

# Get the coefficients of the best model
coef(lasso_model, s = "lambda.min")

# Use the fitted Lasso model to make predictions on the test set
predictions_lasso <- predict(lasso_model, newx = as.matrix(test_scores_df[, c("FP1.1", "FP1.2", "FP1.3", "FP1.4", "FP1.5", "FP2.1", "FP2.2", "FP2.3", "FP2.4", "FP2.5")]), s = "lambda.min", type = "class")

# Build confusion matrix to evaluate performance
confusion_matrix_lasso <- table(predictions_lasso, test_condition)
print(confusion_matrix_lasso)

# Calculate and print the model's accuracy
accuracy_lasso <- sum(predictions_lasso == test_condition) / length(test_condition)
print(accuracy_lasso)

```


Combined FP1 & FP2 Model and Alternative GLMNET Approach

```{r}
## Set seed for reproducibility and prepare FP1 and FP2 data by filtering and arranging by subject, condition, and time.
set.seed(123)  
fp1_data <- firsttrial %>%
  filter(sensor.position == "FP1") %>%
  dplyr::select(name, subject.identifier, matching.condition, time, sensor.value) %>%
  arrange(subject.identifier, matching.condition, name, time)

fp2_data <- firsttrial %>%
  filter(sensor.position == "FP2") %>%
  dplyr::select(name, subject.identifier, matching.condition, time, sensor.value) %>%
  arrange(subject.identifier, matching.condition, name, time)

## Convert the FP1 and FP2 data into matrices.
## Here, each matrix is constructed with 256 time points (rows) and 48 columns (trials or observations).
pca_matrix_fp1 <- matrix(as.numeric(fp1_data$sensor.value), nrow = 256, ncol = 48)
pca_matrix_fp2 <- matrix(as.numeric(fp2_data$sensor.value), nrow = 256, ncol = 48)

pca_fd_fp1 <- smooth.basis(time, pca_matrix_fp1, fdParObj)$fd
pca_fd_fp2 <- smooth.basis(time, pca_matrix_fp2, fdParObj)$fd

## Apply Functional Principal Component Analysis (FPCA) on both FP1 and FP2 functional data objects,
## extracting 5 principal components from each.
res_fp1 <- pca.fd(pca_fd_fp1, nharm = 20)
res_fp2 <- pca.fd(pca_fd_fp2, nharm = 20)

scores_fp1 <- data.frame(res_fp1$scores)
scores_fp2 <- data.frame(res_fp2$scores)

colnames(scores_fp1) <- c("FP1.1", "FP1.2", "FP1.3", "FP1.4", "FP1.5")
colnames(scores_fp2) <- c("FP2.1", "FP2.2", "FP2.3", "FP2.4", "FP2.5")

## Assign a condition factor to the FP1 data based on subject identifier for later partitioning.
fp1_data$condition_factor <- factor(fp1_data$subject.identifier)

## Combine the FP1 ordering data (fp1_order) with the extracted FPCA scores for FP1 and FP2.
fp1modeldata <- cbind(fp1_order, scores_fp1, scores_fp2)

## Create training and testing splits based on the condition factor (which is the subject identifier)
## using a 75% train and 25% test split.
train_indices <- createDataPartition(fp1modeldata$condition_factor, p = 0.75, list = FALSE)
train_data <- fp1modeldata[train_indices, ]
test_data <- fp1modeldata[-train_indices, ]

## First model: Train a multinomial logistic regression model to predict the condition factor
## (subject identifier) using combined FP1 and FP2 principal component scores.
train_model <- multinom(condition_factor ~ 
                          FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5 + 
                          FP2.1 + FP2.2 + FP2.3 + FP2.4 + FP2.5, 
                          data = train_data)

## Generate predictions on the test set using the multinom model,
## then create and print a confusion matrix to assess model performance.
predictions <- predict(train_model, newdata = test_data)

confusion_matrix <- table(predictions, test_data$condition_factor)
print(confusion_matrix)

## Calculate and print the prediction accuracy for the model predicting the condition factor.
accuracy <- sum(predictions == test_data$condition_factor) / length(test_data$condition_factor)
print(accuracy)

## Second model: Re-create fp1modeldata by combining fp1_order with FP1 and FP2 scores (if needed again).
fp1modeldata <- cbind(fp1_order, scores_fp1, scores_fp2)

fp1modeldata <- cbind(fp1_order, scores_fp1, scores_fp2)

train_indices <- createDataPartition(fp1modeldata$subject.identifier, p = 0.75, list = FALSE)
train_data <- fp1modeldata[train_indices, ]
test_data <- fp1modeldata[-train_indices, ]

## Train a multinomial logistic regression model to predict the subject.identifier using the FPCA scores.
train_model <- multinom(subject.identifier ~ 
                          FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5 + 
                          FP2.1 + FP2.2 + FP2.3 + FP2.4 + FP2.5, 
                          data = train_data)


train_model <- glmnet::glmnet(subject.identifier ~ 
                          FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5 + 
                          FP2.1 + FP2.2 + FP2.3 + FP2.4 + FP2.5, 
                          data = train_data)

## Generate predictions using the glmnet model on the test set.
predictions <- predict(train_model, newdata = test_data)

## Build a confusion matrix comparing predictions to the actual subject.identifier in the test set
confusion_matrix <- table(predictions, test_data$subject.identifier)
print(confusion_matrix)

## Calculate and print the prediction accuracy for the glmnet model predicting subject.identifier.
accuracy <- sum(predictions == test_data$subject.identifier) / length(test_data$subject.identifier)
print(accuracy)
```


