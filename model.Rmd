---
title: "R Notebook"
output: html_notebook
---


```{r}
# Define the time grid for 256 points between 0 and 1
time <- seq(0, 1, length.out = 256)

# Define B-spline basis parameters for smoothing FPCA data
norder <- 10
nbasis <- length(time) + norder - 2
basis <- create.bspline.basis(range(time), nbasis, norder, time)

# Define the penalty and smoothing parameter
Lfdobj <- 4    
lambda <- 1e-2
fdParObj <- fdPar(fd(matrix(0, nbasis, 1), basis), Lfdobj, lambda)

# Smoothing helper function: converts a sensor matrix into a functional data object.
smooth_fd <- function(sensor_matrix, time, fdParObj) {
  smooth.basis(time, sensor_matrix, fdParObj)$fd
}
```


```{r}
# Extract FP1 sensor data from firsttrial for FP1
fp1_pca <- firsttrial %>%
  filter(sensor.position == "FP1") %>%
dplyr::  select(name, time, sensor.value)

# Convert sensor values to a matrix (256 time points x 48 trials)
pca_fd_matrix <- matrix(as.numeric(fp1_pca$sensor.value), nrow = 256, ncol = 48)

# Smooth the matrix data to create a functional data object
pca_fd <- smooth.basis(time, pca_fd_matrix, fdParObj)$fd

# Perform FPCA to extract 5 principal components and plot the results
res_fp1 <- pca.fd(pca_fd, nharm = 20)
plot(res_fp1)

```


```{r}
# Extract FP1 sensor data for alcoholics ("a")
alc_data <- firsttrial %>%
  filter(sensor.position == "FP1", subject.identifier == "a") %>%
  dplyr::select(name, time, sensor.value)

# Convert sensor values to a matrix (256 time points x 8 trials)
alc_fd_matrix <- matrix(as.numeric(alc_data$sensor.value), nrow = 256, ncol = 8)

# Assuming 'time' is defined and 'fdParObj' is set
# Smooth the matrix to obtain a functional data object
alc_fd <- smooth.basis(time, alc_fd_matrix, fdParObj)$fd

# Extract FP1 sensor data for controls ("c")
control_data <- firsttrial %>%
  filter(sensor.position == "FP1", subject.identifier == "c") %>%
  dplyr::select(name, time, sensor.value)

# Convert sensor values to a matrix (256 time points x 8 trials)
control_fd_matrix <- matrix(as.numeric(control_data$sensor.value), nrow = 256, ncol = 8)

# Smooth the matrix to obtain a functional data object for controls
control_fd <- smooth.basis(time, control_fd_matrix, fdParObj)$fd

# Perform FPCA for alcoholics (FP1 sensor)
res_alc <- pca.fd(alc_fd, nharm = 20)
plot(res_alc)

# Perform FPCA for controls (FP1 sensor)
res_control <- pca.fd(control_fd, nharm = 20)
plot(res_control)


```


```{r}

# Alcoholics ("a") vs Controls ("c") for FP1 sensor data
t_test_alc_control <- tperm.fd(alc_fd, control_fd)

# Print results for Alcoholics vs Controls comparison
print(t_test_alc_control)


```


```{r}
# Extract FP1 ordering data at time 0 for modeling
fp1_order <- firsttrial %>%
  filter(sensor.position == "FP1") %>%
  dplyr:: select(name, subject.identifier, subject.identifier, time, sensor.value) %>%
  filter(time == 0) %>%
  arrange(subject.identifier, subject.identifier, name)

# Extract the full FP1 time series data
fp1_data <- firsttrial %>%
  filter(sensor.position == "FP1") %>%
 dplyr::  select(name, subject.identifier, subject.identifier, time, sensor.value) %>%
  arrange(subject.identifier, subject.identifier, name, time)

```


```{r}
# Convert FP1 data to a matrix (256 x 48) and smooth it
pca_matrix_fp1 <- matrix(as.numeric(fp1_data$sensor.value), nrow = 256, ncol = 48)
pca_fd_fp1 <- smooth.basis(time, pca_matrix_fp1, fdParObj)$fd

# Run FPCA to extract 5 principal components
resfp1 <- pca.fd(pca_fd_fp1, nharm = 20)
plot(resfp1)

# Extract FPCA scores and prepare modeling data
scores <- data.frame(resfp1$scores)
colnames(scores) <- paste0("FP1.", 1:5)

# Create a factor for the condition based on subject.identifier
fp1_order$condition_factor <- factor(fp1_order$subject.identifier)

# Combine ordering information with FPCA scores
fp1modeldata <- cbind(fp1_order, scores)

# Build a multinomial logistic regression model using FP1 scores
model_fp1 <- multinom(condition_factor ~ FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5, 
                      data = fp1modeldata)
summary(model_fp1)

```


```{r}
# Extract FP2 data
fp2_data <- firsttrial %>%
  filter(sensor.position == "FP2") %>%
  dplyr:: select(name, subject.identifier, subject.identifier, time, sensor.value) %>%
  arrange(subject.identifier, subject.identifier, name, time)

# Convert FP2 sensor data into a matrix (256 x 48) and smooth it
pca_matrix_fp2 <- matrix(as.numeric(fp2_data$sensor.value), nrow = 256, ncol = 48)
pca_fd_fp2 <- smooth.basis(time, pca_matrix_fp2, fdParObj)$fd

# Run FPCA on FP2 data to extract 5 principal components
resfp2 <- pca.fd(pca_fd_fp2, nharm = 20)
plot(resfp2)

# Extract FP2 scores
scores2 <- data.frame(resfp2$scores)
colnames(scores2) <- paste0("FP2.", 1:5)

```


```{r}
# Combine FP1 ordering data with FP1 and FP2 FPCA scores
fp1modeldata <- cbind(fp1_order, scores, scores2)

# Build a multinom model predicting subject identifier using combined scores
model_combined <- multinom(subject.identifier ~ FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5 +
                             FP2.1 + FP2.2 + FP2.3 + FP2.4 + FP2.5, 
                           data = fp1modeldata)
summary(model_combined)

```

```{r}
## Extract FP1 sensor data at time 0, arrange by subject and condition for modeling
 
fp1_order <- firsttrial %>%
  filter(sensor.position == "FP1") %>%
  dplyr::select(name,subject.identifier, subject.identifier, time, sensor.value) %>%
  filter(time==0) %>%
  arrange(subject.identifier, subject.identifier, name)

fp1_data <- firsttrial %>%
  filter(sensor.position == "FP1") %>%
  dplyr::select(name,subject.identifier, subject.identifier, time, sensor.value) %>%
  arrange(subject.identifier, subject.identifier, name, time)

## Convert the FP1 time series data into a matrix form and smooth it to get the functional data object
pca_matrix <- matrix(as.numeric(fp1_data$sensor.value), 
                     nrow = 256, ncol = 48)

## Apply FPCA to extract 5 principal components and plot the FPCA results
pca_fd <- smooth.basis(time, pca_matrix, fdParObj)$fd
resfp1 <- pca.fd(pca_fd, nharm = 20)

plot(resfp1)


scores <- data.frame(resfp1$scores)
colnames(scores) <- c("FP1.1", "FP1.2", "FP1.3", "FP1.4", "FP1.5")
fp1_order$condition_factor <- factor(fp1_order$subject.identifier)
#condition <- c(rep("S1 obj", 16), rep("S2 match", 16), rep("S2 No match,", 16))
#condition_factor <- factor(condition, levels = c("S1 obj", "S2 match", "S2 No match,"))
fp1modeldata = cbind(fp1_order,scores)

model <- multinom(condition_factor ~ FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5, data = fp1modeldata)


summary(model)
```

Building a Multinomial Model with FP1 and FP2 Data

```{r}
fp2_data <- firsttrial %>%
  filter(sensor.position == "FP2") %>%
  dplyr::select(name,subject.identifier, subject.identifier, time, sensor.value) %>%
  arrange(subject.identifier, subject.identifier, name, time)

## Convert the FP2 data into a matrix and smooth it to create a functional data object
pca_matrix <- matrix(as.numeric(fp2_data$sensor.value), 
                     nrow = 256, ncol = 48)


pca_fd <- smooth.basis(time, pca_matrix, fdParObj)$fd
resfp2 <- pca.fd(pca_fd, nharm = 20)

plot(resfp2)


scores2 <- data.frame(resfp2$scores)
colnames(scores2) <- c("FP2.1", "FP2.2", "FP2.3", "FP2.4", "FP2.5")

fp1modeldata = cbind(fp1_order,scores, scores2)

## Build a multinomial logistic regression model to predict subject identifier using combined FP1 & FP2 scores
model <- multinom(subject.identifier ~ FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5 + FP2.1 + FP2.2 + FP2.3 + FP2.4 + FP2.5, data = fp1modeldata)


summary(model)
```

Train-Test Split and Model Evaluation

```{r}

set.seed(123)  
 # clustering functions kmeans etc

## Partition the data into 75% training and 25% testing based on subject.identifier
train_indices <- createDataPartition(fp1modeldata$subject.identifier, p =0.75, list=F) #subject.identifier and subject identifier

as.vector(train_indices)

train_scores <- fp1modeldata[train_indices, ]
test_scores <- fp1modeldata[-train_indices, ]
train_condition <- train_scores$condition_factor
test_condition <- test_scores$condition_factor



train_scores_df <- data.frame(train_scores)
test_scores_df <- data.frame(test_scores)

## Partition the data into 75% training and 25% testing based on subject.identifier
train_model_fp1 <- multinom(train_condition ~ FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5 , data = train_scores_df)

## Generate predictions on the test set and create a confusion matrix to evaluate performance
predictions <- predict(train_model_fp1, newdata = test_scores_df)


confusion_matrix <- table(predictions, test_condition)
print(confusion_matrix)


## Calculate and print the model's prediction accuracy
accuracy <- sum(predictions == test_condition) / length(test_condition)
print(accuracy)


```

Multinomial Model Using FP2 Scores Only

```{r}

## Train a multinomial logistic regression model using only the FP2 principal component scores.
## The model predicts the subject.identifier (stored in 'train_condition') based on FP2 scores
train_model_fp2 <- multinom(train_condition ~ FP2.1 + FP2.2 + FP2.3 + FP2.4 + FP2.5 , data = train_scores_df)


predictions <- predict(train_model_fp2, newdata = test_scores_df)

## Create a confusion matrix to compare predictions to actual test conditions.
confusion_matrix <- table(predictions, test_condition)
print(confusion_matrix)

## Calculate and print the accuracy of the FP2 model on the test set.
accuracy <- sum(predictions == test_condition) / length(test_condition)
print(accuracy)
```

Multinomial Model Using FP1 Scores Only

```{r}
## Partition the data based on subject identifier (via condition_factor) into training and test sets.
## 'fp1_order' contains FP1 data at time 0; we use this along with FPCA scores.
train_indices <- createDataPartition(fp1modeldata$subject.identifier, p =0.75, list=F) #subject.identifier and subject identifier

as.vector(train_indices)

train_scores <- fp1modeldata[train_indices, ]
test_scores <- fp1modeldata[-train_indices, ]
train_condition <- train_scores$condition_factor
test_condition <- test_scores$condition_factor



train_scores_df <- data.frame(train_scores)
test_scores_df <- data.frame(test_scores)

## Train a multinomial logistic regression model using FP1 principal component scores.
## This model predicts the subject.identifier (condition_factor) from FP1 scores.
train_model_fp1 <- multinom(train_condition ~ FP1.1 + FP1.2 + FP1.3 + FP1.4 + FP1.5 , data = train_scores_df)

## Predict subject.identifiers on the test dataset using the FP1 model.
predictions <- predict(train_model_fp1, newdata = test_scores_df)

## Build a confusion matrix to compare predicted vs. actual subject.identifiers.
confusion_matrix <- table(predictions, test_condition)
print(confusion_matrix)

## Calculate and print the model accuracy for the FP1-based predictions
accuracy <- sum(predictions == test_condition) / length(test_condition)
print(accuracy)

```

accuracy really low above


```{r}
# Extract the scores and convert them to a matrix
predictors <- as.matrix(fp1modeldata[, c("FP1.1", "FP1.2", "FP1.3", "FP1.4", "FP1.5", "FP2.1", "FP2.2", "FP2.3", "FP2.4", "FP2.5")])

# Convert the outcome variable into a factor for multinomial regression
response <- as.factor(fp1modeldata$subject.identifier)

# Fit the Lasso model with cross-validation
lasso_model <- cv.glmnet(predictors, response, alpha = 1, family = "multinomial", type.measure = "class")

# Print the best lambda value
print(paste("Best lambda: ", lasso_model$lambda.min))

# Get the coefficients of the best model
coef(lasso_model, s = "lambda.min")

# Use the fitted Lasso model to make predictions on the test set
predictions_lasso <- predict(lasso_model, newx = as.matrix(test_scores_df[, c("FP1.1", "FP1.2", "FP1.3", "FP1.4", "FP1.5", "FP2.1", "FP2.2", "FP2.3", "FP2.4", "FP2.5")]), s = "lambda.min", type = "class")

# Build confusion matrix to evaluate performance
confusion_matrix_lasso <- table(predictions_lasso, test_condition)
print(confusion_matrix_lasso)

# Calculate and print the model's accuracy
accuracy_lasso <- sum(predictions_lasso == test_condition) / length(test_condition)
print(accuracy_lasso)

```